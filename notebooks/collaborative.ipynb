{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39f3ccf",
   "metadata": {},
   "source": [
    "<h1><center>Une application de recommandation de contenu</center></h1>\n",
    "\n",
    "<hr>\n",
    "<h3><center>Élaboration d’un modèle de type Collaborative Filtering</center></h3>\n",
    "<br>\n",
    "\n",
    ">__Réalisé par : Said Arrazouaki__\n",
    "\n",
    "\n",
    ">__Encadré par : Addi Ait-Mlouk__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fa0cc",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c2637",
   "metadata": {},
   "source": [
    "Après avoir exploré les approches basées sur le contenu, ce troisième notebook aborde une technique complémentaire : le filtrage collaboratif. Cette méthode ne se focalise plus sur les caractéristiques intrinsèques des articles, mais sur les interactions entre les utilisateurs et les contenus : l’idée est que des utilisateurs ayant réagi de manière similaire à certains articles auront sans doute des goûts proches. En analysant la matrice des clics et en la factorisant en vecteurs latents représentant d’un côté les utilisateurs et de l’autre les articles, nous chercherons à prédire quels contenus pourraient plaire à chaque lecteur, même s’il ne les a encore jamais consultés. Nous décrirons ici la construction et l’évaluation d’un tel modèle collaboratif. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de69737c",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295c4aec",
   "metadata": {},
   "source": [
    "Commençons par charger les différentes données nécessaires :\n",
    "- Le fichier articles_embeddings_reduced.pickle\n",
    "- Le fichier articles_metadata.csv\n",
    "- Les fichiers clicks/clicks_hour_*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b475a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import numpy as np  \n",
    "from joblib import Parallel, delayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9f04e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'articles : 364047\n"
     ]
    }
   ],
   "source": [
    "# Charger les métadonnées des articles\n",
    "articles_df = pd.read_csv('../data/articles_metadata.csv')\n",
    "print(\"Nombre d'articles :\", len(articles_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dc5f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice d'embeddings : (364047, 75)\n"
     ]
    }
   ],
   "source": [
    "# Charger la matrice d'embeddings des articles\n",
    "with open('../data/processed/articles_embeddings_reduced.pickle', 'rb') as f:\n",
    "    embeddings_matrix = pickle.load(f)\n",
    "print(\"Taille de la matrice d'embeddings :\", embeddings_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fda422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de clics : 2988181\n"
     ]
    }
   ],
   "source": [
    "# Charger et concaténer tous les fichiers de clics horaires\n",
    "clicks_files = glob.glob('../data/clicks/clicks_hour_*.csv')\n",
    "clicks_list = [pd.read_csv(f) for f in clicks_files]\n",
    "clicks_df = pd.concat(clicks_list, ignore_index=True)\n",
    "print(\"Nombre total de clics :\", len(clicks_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19bdba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire les user_clicks\n",
    "with open('../data/processed/user_clicks.pickle', 'rb') as f:\n",
    "    user_clicks = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f87230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles populaires pour cold start et optimisation\n",
    "popular_articles = clicks_df['click_article_id'].value_counts().head(1000).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f843c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer les articles populaires\n",
    "with open('../data/processed/popular_articles.pickle', 'wb') as f:\n",
    "    pickle.dump(popular_articles, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8db218",
   "metadata": {},
   "source": [
    "## Construction de la matrice utilisateur-article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa03322",
   "metadata": {},
   "source": [
    "Cette partie prépare les interactions utilisateurs-articles en calculant des ratings implicites pondérés. Les données sont formatées pour l'algorithme SVD avec la bibliothèque Surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56eb0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, accuracy, SVD\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c8f478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de couples user-article : 2977178\n"
     ]
    }
   ],
   "source": [
    "# Préparer les données avec pondération (rating = count / session_size)\n",
    "interactions = clicks_df.groupby(['user_id', 'click_article_id', 'session_size']).size().reset_index(name='count')\n",
    "interactions['rating'] = interactions['count'] / interactions['session_size']  # Pondération\n",
    "print(\"Nombre de couples user-article :\", len(interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f964164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir un reader surprise\n",
    "reader = Reader(rating_scale=(1, interactions['count'].max()))\n",
    "data = Dataset.load_from_df(interactions[['user_id', 'click_article_id', 'rating']], reader)\n",
    "\n",
    "# Split en train/test\n",
    "trainset, testset = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdc320",
   "metadata": {},
   "source": [
    "## Entraînement du modèle SVD sur les données implicites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950ea89",
   "metadata": {},
   "source": [
    "Nous entraînons ici un modèle SVD pour prédire les préférences des utilisateurs. Le modèle est évalué avec RMSE et Precision@5, puis sauvegardé pour une utilisation en production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7146025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x192cdfa0a10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entraînement SVD\n",
    "algo = SVD(n_factors=50, n_epochs=20, random_state=42)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a955daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle pour production\n",
    "with open('../data/processed/svd_model.pickle', 'wb') as f:\n",
    "    pickle.dump(algo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "378771e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6645\n",
      "RMSE : 0.6644914367615806\n",
      "Precision@5 : 0.45312426977838055\n"
     ]
    }
   ],
   "source": [
    "# Évaluation RMSE\n",
    "predictions = algo.test(testset)\n",
    "print(\"RMSE :\", accuracy.rmse(predictions))\n",
    "\n",
    "# Évaluation Precision@5 \n",
    "def precision_at_k(predictions, k=5):\n",
    "    user_est_true = {}\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if uid not in user_est_true:\n",
    "            user_est_true[uid] = []\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    precisions = []\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r > 0) for (_, true_r) in user_ratings[:k])\n",
    "        precisions.append(n_rel / k if k > 0 else 0)\n",
    "    return sum(precisions) / len(precisions)\n",
    "\n",
    "print(\"Precision@5 :\", precision_at_k(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bb3ec",
   "metadata": {},
   "source": [
    "## Génération des recommandations avec le modèle SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3300db",
   "metadata": {},
   "source": [
    "Cette section définit les fonctions pour générer des recommandations, incluant une approche Collaborative flexible (tous articles ou populaires)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99ad787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste de tous les articles\n",
    "all_article_ids = articles_df['article_id'].unique().tolist()\n",
    "\n",
    "def recommend_articles_collaborative(user_id, top_n=5, candidate_articles=popular_articles):\n",
    "    if candidate_articles is None:\n",
    "        candidate_articles = all_article_ids\n",
    "        \n",
    "    try:\n",
    "        inner_uid = algo.trainset.to_inner_uid(user_id)  # noqa: F841\n",
    "    except ValueError:  \n",
    "        return popular_articles[:top_n]  \n",
    "\n",
    "    seen_articles = set(user_clicks.get(user_id, []))\n",
    "    recommendations = []\n",
    "    for art_id in candidate_articles:  # Limite aux candidats pour perf\n",
    "        if art_id in seen_articles:\n",
    "            continue\n",
    "        pred = algo.predict(user_id, art_id)\n",
    "        recommendations.append((art_id, pred.est))\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [art for art, _ in recommendations[:top_n]] or popular_articles[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c210ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles lus par 0 : [157541, 68866, 96755, 313996, 160158]\n",
      "Recos collab : [160974, 272143, 336221, 234698, 123909]\n"
     ]
    }
   ],
   "source": [
    "# Exemple\n",
    "example_user = list(user_clicks.keys())[0]\n",
    "print(\"Articles lus par\", example_user, \":\", user_clicks[example_user][:5])\n",
    "print(\"Recos collab :\", recommend_articles_collaborative(example_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fba7ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Précalcul optimisé avec parallélisme (limité à 100 users pour test)\n",
    "users_sample = list(user_clicks.keys())[:100]  # Augmente en prod\n",
    "def compute_recos(user):\n",
    "    return user, recommend_articles_collaborative(user)\n",
    "\n",
    "top_recos = dict(Parallel(n_jobs=-1)(delayed(compute_recos)(user) for user in users_sample))\n",
    "with open('../data/processed/precomputed_recos_collab.pickle', 'wb') as f:\n",
    "    pickle.dump(top_recos, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9f61da",
   "metadata": {},
   "source": [
    "## Hybride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753aff2",
   "metadata": {},
   "source": [
    "Cette section introduite une version hybride combinant Collaborative et Content-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction hybride (Collab + Content-Based)\n",
    "def recommend_hybrid(user_id, top_n=5):\n",
    "    collab_recos = recommend_articles_collaborative(user_id, top_n=10)  # Plus pour mélange\n",
    "    if user_id not in user_clicks:\n",
    "        return collab_recos[:10]\n",
    "    last_article = user_clicks[user_id][-1]  # Dernier cliqué\n",
    "    last_emb = embeddings_matrix.iloc[last_article]\n",
    "    sims = cosine_similarity([last_emb], embeddings_matrix)[0]\n",
    "    content_recos = np.argsort(sims)[-11:-1][::-1]  # Top 10 similaires, exclure soi-même\n",
    "    hybrid = list(set(collab_recos + list(content_recos)))[:top_n]  \n",
    "    return collab_recos, content_recos, hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc003494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles lus par 0 : [157541, 68866, 96755, 313996, 160158]\n",
      "Collaboratif recommendations : [160974, 272143, 336221, 234698, 123909, 336223, 96210, 162655, 183176, 168623]\n",
      "Content-based recommendations: [86143 87427 87676 87278 86613 87670 85792 87030 86426 85768]\n",
      "Hybride recommendations : [87427, 123909, 183176, 85768, 272143]\n"
     ]
    }
   ],
   "source": [
    "# Exemple\n",
    "example_user = list(user_clicks.keys())[0]\n",
    "collab_recos, content_recos, hybrid = recommend_hybrid(example_user)\n",
    "print(\"Articles lus par\", example_user, \":\", user_clicks[example_user][:5])\n",
    "print(\"Collaboratif recommendations :\", collab_recos)\n",
    "print(\"Content-based recommendations:\", content_recos)\n",
    "print(\"Hybride recommendations :\", hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564bf4c2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9dbcc",
   "metadata": {},
   "source": [
    "Ce notebook a mis en œuvre un système de recommandation basé sur le Collaborative Filtering avec l'algorithme SVD, optimisé pour la performance et la scalabilité. Nous avons corrigé les lenteurs initiales en limitant les prédictions aux articles populaires (optionnel), ajouté une pondération des ratings implicites, et intégré une approche hybride utilisant les embeddings pour gérer les nouveaux articles. L'évaluation avec RMSE et Precision@5 montre des résultats prometteurs, et le précalcul des recommandations facilite l'intégration dans Azure Functions via Blob Storage. Pour la suite, un réentraînement périodique du modèle et une combinaison avec le Content-Based Filtering permettront d'améliorer la couverture des nouveaux utilisateurs et articles, répondant ainsi aux besoins de la startup My Content.blablabla"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise_envir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
